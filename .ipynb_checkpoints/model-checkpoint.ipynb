{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7b0ab8-0beb-4f57-a8f6-5037b2fdd027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.0\n",
      "  Using cached numpy-1.26.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (99 kB)\n",
      "Requirement already satisfied: tensorflow in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (5.29.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: rich in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nicholaskunze/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Using cached numpy-1.26.0-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.0\n",
      "    Uninstalling numpy-2.3.0:\n",
      "      Successfully uninstalled numpy-2.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "statsmodels 0.14.0 requires scipy!=1.9.2,>=1.4, which is not installed.\n",
      "scikit-learn 1.2.2 requires scipy>=1.3.2, which is not installed.\n",
      "fuzzytm 2.0.9 requires pyfume, which is not installed.\n",
      "fuzzytm 2.0.9 requires scipy, which is not installed.\n",
      "scikit-image 0.20.0 requires PyWavelets>=1.1.1, which is not installed.\n",
      "scikit-image 0.20.0 requires scipy>=1.8; python_version > \"3.9\", which is not installed.\n",
      "matplotlib 3.10.3 requires contourpy>=1.0.1, which is not installed.\n",
      "imbalanced-learn 0.11.0 requires scipy>=1.5.0, which is not installed.\n",
      "miniful 0.0.6 requires scipy>=1.0.0, which is not installed.\n",
      "bokeh 3.3.0 requires contourpy>=1, which is not installed.\n",
      "sentence-transformers 4.1.0 requires scipy, which is not installed.\n",
      "simpful 2.12.0 requires scipy>=1.0.0, which is not installed.\n",
      "datashader 0.16.0 requires numba, which is not installed.\n",
      "datashader 0.16.0 requires scipy, which is not installed.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.0 tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c2180c-457c-471b-8185-ee75f194af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nicholaskunze/Desktop/MorningChatBot/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4680d1-4d41-414b-a7de-710da55495ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import nltk \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f34bd-c932-414c-9363-a34bcfe32ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Model => Gives 77% Accuracy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9a902346-5993-41d8-9eb7-79bad8ff525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingHelper: \n",
    "\n",
    "    def __init__(self, labels): \n",
    "        self.labels = labels\n",
    "    \n",
    "    def read_in_json(self, data_src): \n",
    "        # Read in the data \n",
    "        f = open(data_src, \"r\")\n",
    "        json_data = f.read()\n",
    "        f.close()\n",
    "\n",
    "        data = json.loads(json_data)\n",
    "        df = pd.json_normalize(data['intents'])\n",
    "\n",
    "        df_sentences = pd.DataFrame({\"label\": [], \"input\": []})\n",
    "\n",
    "        labels = []\n",
    "        inputs = []\n",
    "    \n",
    "\n",
    "        for index, row in df.iterrows(): \n",
    "            for sentence in row[\"input\"]:\n",
    "                labels.append(row[\"label\"])\n",
    "                inputs.append(sentence)\n",
    "            \n",
    "        df_sentences[\"label\"] = labels\n",
    "        df_sentences[\"input\"] = inputs\n",
    "    \n",
    "        return df_sentences\n",
    "\n",
    "    # Function that encodes labels as One Hot Vectors\n",
    "    def one_hot_labels(self, sentence): \n",
    "        return [1 if sentence == label else 0 for label in self.labels]\n",
    "\n",
    "    def fill_bag_of_words(self,table): \n",
    "        vocabulary = []\n",
    "        for row in table:\n",
    "            for word in row: \n",
    "                vocabulary.append(word)\n",
    "        return [x for x in set(vocabulary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b833818b-bb77-4d8e-b488-02b1aa178014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBotHelper: \n",
    "\n",
    "    def __init__(self, bag_of_words): \n",
    "        self.bag_of_words = bag_of_words\n",
    "    \n",
    "    @staticmethod\n",
    "    def nlp_preprocessing(sentence): \n",
    "\n",
    "        tokens = nltk.word_tokenize(sentence) \n",
    "\n",
    "        lowercased_tokens = [token.lower() for token in tokens]\n",
    "        \n",
    "        filtered_tokens_stopwords = [token for token in lowercased_tokens if token not in stopwords]\n",
    "\n",
    "        filtered_tokens = [token for token in filtered_tokens_stopwords if token not in string.punctuation]\n",
    "\n",
    "        filtered_tokens_two = [token for token in filtered_tokens if token not in [\"'\",\"'s\", \"’\"]]\n",
    "\n",
    "        return filtered_tokens_two\n",
    "        \n",
    "    \n",
    "    def embed(sentence):\n",
    "        return [1 if word in sentence else 0 for word in self.bag_of_words]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2a4bffea-63d3-4c40-8d1f-88c432747189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "helper = PreprocessingHelper(['greeting', 'breakfast','weather','news', 'motivation'])\n",
    "training_data = helper.read_in_json(\"Data/training_data.json\")\n",
    "training_data[\"label\"] = training_data[\"label\"].apply(lambda x: helper.one_hot_labels(x))\n",
    "training_data[\"input\"] = list(training_data[\"input\"].apply(lambda x: ChatBotHelper.nlp_preprocessing(x)))\n",
    "bag_of_words = helper.fill_bag_of_words(training_data[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0952bac0-74da-4e9a-a85d-3b3370ebb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Training Set \n",
    "chatbot_helper = ChatBotHelper(bag_of_words)\n",
    "X_train = np.array([embed(x) for x in training_data[\"input\"]])\n",
    "y_train = np.array([x for x in training_data[\"label\"]])\n",
    "\n",
    "test_data = helper.read_in_json(\"Data/test_data.json\")\n",
    "X_test = np.array([embed(x) for x in test_data[\"input\"]])\n",
    "y_test = np.array([helper.one_hot_labels(x) for x in test_data[\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "76808768-b534-4acc-951c-08e735444574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "mymodel = Sequential([\n",
    "    Dense(384, activation='relu'), # 107\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "]) \n",
    "\n",
    "#mymodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#mymodel.fit(X_train, y_train, epochs=100, batch_size=20)\n",
    "#mymodel.evaluate(X_test, y_test)\n",
    "# 76% Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cf98e448-5c05-40eb-ba3f-04600d9af1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "94f148e5-c69f-458b-af8e-9c54ce00bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = mymodel.predict(X_test) \n",
    "pred = np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "235aedb1-b0e9-4b17-b675-4b8f6ea2d941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            Hi!\n",
       "1                                How’s it going?\n",
       "2                                         Hello!\n",
       "3                              Nice to meet you!\n",
       "4                                     What’s up?\n",
       "5                   Do I need an umbrella today?\n",
       "6                     Will it be chilly outside?\n",
       "7               Should I prepare for rain later?\n",
       "8                   What’s the weather forecast?\n",
       "9             Is it going to be sunny or cloudy?\n",
       "10                        Any big stories today?\n",
       "11                 What’s happening in the news?\n",
       "12                  Update me on today’s events.\n",
       "13             Can you share the latest updates?\n",
       "14                  What’s the buzz in the news?\n",
       "15                I’m feeling a bit unmotivated.\n",
       "16           Can you share some uplifting words?\n",
       "17                           Inspire me, please.\n",
       "18               I could use some encouragement.\n",
       "19                 Help me find some motivation.\n",
       "20              What’s a tasty breakfast option?\n",
       "21    I want to try something new for breakfast.\n",
       "22      Any suggestions for a healthy breakfast?\n",
       "23        What can I make quickly for breakfast?\n",
       "24        Can you give me an idea for breakfast?\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1f8e0eca-1297-415e-9811-4fc93679c846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7bc53c1f-939e-4bec-9201-8186b50d5121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 0, 0, 2, 1, 2, 2, 1, 2, 2, 2, 3, 1, 2, 3, 2, 0, 3, 2, 2,\n",
       "       2, 2, 2])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9789a4e8-c2f6-45b1-9712-d2e413fdba0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 1],\n",
       "       [2, 0, 2, 1, 0],\n",
       "       [0, 5, 3, 3, 2],\n",
       "       [1, 0, 0, 1, 2],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred, np.argmax(y_test, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
